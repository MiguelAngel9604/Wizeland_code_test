# -*- coding: utf-8 -*-
"""Copia de Copia de Copia de Code_Challenge_Student.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/153RpFC3mWlUFUd3vPOr0VIDsbLD9vRxc

#Data Bootcamp Selection Challenge
#####In this challenge you will calculate various KPIs using a car based dataset, each question will have a single correct answer that will be evaluated through automated unit testing. Use the dictionary provided below to fill in your answers, each question will state the format required for the answer and examples are provided so you know how properly fill the answer dictionary. 
#####**Use the dataset "as is" and do not perform any data cleaning or modify it in any way, doing so could make you answer all your questions incorrectly. Do not modify the structure of the answer dictionary.**

#####When you finish this challenge please upload both your notebook and your answer dictionary in pickle format to a public github repository submit their URL to the [google form](https://forms.gle/wWysZEMkoZsjB11Y7) that was provided to you.

##### Some unit tests are provided at the end of this notebook to help you verify your answers are in the correct format, however they will not test everything.
"""

#Use this dictionary to store your answers in the correct format in the cells below , do not modify the keys
answer_dict =  {"Q1" : None,
                "Q2" : None,
                "Q3" : None,
                "Q4" : None,
                "Q5" : None,
                "Q6" : None,
                "Q7" : None}

"""##Reading the dataset
#####An example is provided to read the dataset using [pandas](https://pandas.pydata.org/), while we reccommend using pandas you may use any python library to solve this challenge. 
"""

import pandas as pd
import numpy as np
url='https://drive.google.com/file/d/1PCJ7ltluquoXKi6MYTPMfwZQNI_-MIFP/view?usp=sharing'
url='https://drive.google.com/uc?id=' + url.split('/')[-2]
df = pd.read_csv(url)

df.head()

df.info()

"""##Q1. What is the average CO2 emmission per gram/mile of all Volkswagen cars?

##### Format: A floating number
##### Example answer:
 `11.547`
"""

########## Q1
#1.- Deleting white spaces and / in column names
df.columns = df.columns.str.replace(' ','_')
df.columns = df.columns.str.replace('/','_')

#2.- Creating parquet
df.to_parquet('df.parquet.gzip',
              compression='gzip')  
pd.read_parquet('df.parquet.gzip')  

#Example answer:
#answer_dict["Q1"] =  11.547

# Install dependencies
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz 
!tar -xvf spark-3.1.2-bin-hadoop3.2.tgz
!pip install -q findspark
!pip install pyspark

#Creating Spark session
#I decided to use pyspark and pandas to do all the exercices and advantage of both, I'll be using the same session in all the questions and logic.
from pyspark.sql import SparkSession
from pyspark.sql import functions as f
from pyspark.sql.functions import *
from pyspark.sql.types import StringType, IntegerType
import pyspark
from pyspark import SparkContext
from pyspark import SparkConf

sc = SparkContext()
spark = SparkSession.builder.getOrCreate()

#Creating View "Cars" with all the dataframe info
df_reviews = spark.read.options(header=True).parquet(
    'df.parquet.gzip'
)
df_reviews.createOrReplaceTempView("cars")

#Reading spark sql
CO2_AVG = spark.sql(
    """
    SELECT 
      AVG(CO2_Emission_Grams_Mile)
    FROM cars 
    where Make = "Volkswagen"
    """
)
spark.conf.set("spark.sql.execution.arrow.enabled", "true")

#Setting float type to result
answer_dict["Q1"] =  float(CO2_AVG.collect()[0][0])
answer_dict["Q1"]

"""##Q2. Calculate the top 5 brands(Make) with the most unique models, order your answer in descending order with respect to the number of unique models.
##### **NOTE:** Consider only the name of the models and their brand, that is use only the Make and Model columns
##### Format: A 5X2 list with each row being the name of the brand followed by the unique number of models, in descending order.
#####Hint: You can use the pandas [df.values.tolist()](https://pandas.pydata.org/docs/reference/api/pandas.Series.tolist.html) function to format your answer.

##### Example answer: 
`[["Volkswagen", 1000], ["Toyota", 900], ["Honda", 800], ["Subaru", 700], ["Ford", 600]]`
"""

########## Q2
#Your code here
#Reading spark sql 
top_brands = spark.sql(
    """
    SELECT 
      Make, count(distinct Model) as Brand_number
    FROM cars 
    group by Make
    Order by count(distinct Model) desc
    limit 5
    """
)

top_brands_df = top_brands.toPandas()

#Example answer:
#answer_dict["Q2"] =  [["Volkswagen", 1000], ["Toyota", 900], ["Honda", 800], ["Subaru", 700], ["Ford", 600]]

#Setting result in list format
answer_dict["Q2"] = top_brands_df.values.tolist()
answer_dict["Q2"]

"""##Q3. What are all the different types of fuels in the dataset sorted alphabetically?
##### Format: A list of strings sorted alphabetically.
##### Example Answer: 
`['Regular',
 'Premium']`
"""

########## Q3
#Your code here
fuel_types = spark.sql(
    """
    SELECT 
      distinct fuel_type
    FROM cars 
    Order by fuel_type asc
    """
)

fuel_types_df = fuel_types.toPandas()
#answer_dict["Q3"] =  ['Regular', 'Premium']

#Mapping each result to string
answer_dict["Q3"] =  list(map(''.join, fuel_types_df['fuel_type']))
answer_dict["Q3"]

"""##Q4. Show the 9 Toyota cars with the most extreme Fuel Barrels/Year in abosolute terms within all Toyota cars. Show the car Model, Year and their Fuel Barrels/Year in standard deviation units([Z-score](https://fredclavel.org/2019/03/18/basics-standardization-and-the-z-score/)) **sorted** in descending order by their Fuel Barrels/Year in absolute terms first and then by year in descending order **BUT** without modifying the negative values (see example).

##### Format: A 9X3 list with each row containing the Model, Year and Fuel Barrels/Year in standard deviations units

##### Example answer: 
```
[['DJ Po Vehicle 2WD', 2004, -6.407431084026927],
 ['FJ8c Post Office', 2003, -6.407431084026927],
 ['Post Office DJ5 2WD', 2005, -6.391684618442447],
 ['Sierra 2500 Hd 2WD', 2002, -6.391684618442447],
 ['Camry CNG', 2012, 2.677633075759575],
 ['Sierra 1500 4WD', 2005, 2.677633075759575],
 ['Sierra 1500 4WD', 2001, 2.677633075759575],
 ['V15 Suburban 4WD', 1988, 2.677633075759575],
 ['V15 Suburban 4WD', 1987, 2.677633075759575]]
```
#####Note that while the list is sorted by the Fuel Barrels/Year in absolute terms and in standard deviation units, the values are not modified. If the values are the same the rows are sorted by the year.

"""

########## Q4
#Reading spark sql
toyota_barrels = spark.sql(
    """
    SELECT 
      Model, Year, Fuel_Barrels_Year
    FROM cars 
    where Make = 'Toyota'
   
    """
)

toyota_barrels_df = toyota_barrels.toPandas()
toyota_barrels_df

#Getting mean
mean = toyota_barrels_df["Fuel_Barrels_Year"].mean()
mean

#Getting standard
std = toyota_barrels_df["Fuel_Barrels_Year"].std()
std

#Calculating z_score
z_score = toyota_barrels.withColumn("z_score", (col("Fuel_Barrels_Year") - mean) / std)
z_score.show(10)

toyota_barrels_df = z_score.toPandas()
toyota_barrels_df

#Order by abs number z_score
zscore_list = toyota_barrels_df.iloc[(-toyota_barrels_df['z_score'].abs()).argsort()].reset_index(drop=False).head(9)
zscore_list

#Filtering just the columns I need
df_columns = zscore_list[['Model', 'Year', 'z_score']]
df_columns

#I tried different ways to do sort the year column after sorting the z_score column but I was not able to get the result I needed
# I tried using sort() function, iloc[], Loops, and more combinations but unfurtunality none of them worked so I decided to send the result without the second reuirement.

#Setting value to QA
answer_dict["Q4"] =  df_columns.values.tolist()
answer_dict["Q4"]

"""##Q5. Calculate the changes in Combined MPG with their previous model of all Golf cars with Manual 5-spd transmission and Regular Fuel Type. Show the Year, the Combined MPG and the calculated difference of MPG in a list sorted by Year in ascending order.

##### Format: A 19X3 list, with the Year and Combined MPG being of type integer **and only the calculated difference is of type float**
##### **Note: The value for the first model should be 0.** It does not matter that there are gaps in the years, calculate with respect the previous model.

#####Example answer:



```
[[1986, 25, 0.0],
 [1987, 25, 0.0],
 [1988, 25, 0.0],
 [1989, 25, 0.0],
 [1990, 23, -2.0],
 [1991, 23, 0.0],
 [1992, 24, 1.0],
 [1993, 25, 1.0],
 [1994, 25, 0.0],
 [1995, 25, 0.0],
 [1996, 25, 0.0],
 [1997, 25, 0.0],
 [1998, 24, -1.0],
 [1999, 25, 1.0],
 [2000, 24, -1.0],
 [2001, 24, 0.0],
 [2002, 24, 0.0],
 [2004, 24, 0.0],
 [2006, 24, 0.0]]
```




"""

########## Q5
#Your code here
#Reading spark sql
golf_cars = spark.sql(
    """
    SELECT 
      Year,Combined_MPG
    FROM cars 
    where Model = 'Golf' and Transmission = 'Manual 5-spd' and Fuel_Type = 'Regular'
   order by Year asc
    """
)

golf_cars_df = golf_cars.toPandas()

#Getting difference between Combined MPG
difference = golf_cars_df.diff(axis=0);
golf_cars_df["Difference"] = difference["Combined_MPG"]

#Setting datatypes
golf_cars_types_df = golf_cars_df.astype({"Year": int, "Combined_MPG": int})

#Cleaning nan values
golf_cars_types_df['Difference'] = golf_cars_types_df['Difference'].replace(np.nan, 0.0)
golf_cars_types_df

#Setting result to Q5
answer_dict["Q5"] =  list(map(list, golf_cars_types_df.itertuples(index=False)))
answer_dict["Q5"]

"""##Q6. What are the top 5 lowest CO2 Emission Grams/Mile emmisions of cars for each of the following brands: Toyota, Ford, Volkswagen, Nissan, Honda

#####Format: A 5X6 list with the first element of each row being the Make of the cars and the following five values being floats sorted in ascending order. The Makes should appear in order listed in the question starting with Toyota and ending with Honda (see example).

#####Example answer:

```
[['Toyota', 100.0, 140.0, 140.0, 150.0, 150.0],
 ['Ford',
  100.025641025641,
  200.677633075759575,
  200.677633075759575,
  200.677633075759575,
  200.677633075759575],
 ['Volkswagen', 139.0, 154.0, 166.5, 166.5, 166.5],
 ['Nissan', 122.0, 122.0, 122.0, 122.0, 160.0],
 ['Honda', 100.0, 100.0, 100.0, 100.0, 123.91684618442447]]
```





"""

########## Q6
#Your code here
#In this exercise I tried to convert the list to float but due to the time I could not finished and I had to apply a for each in the rows.
toyota_cars = spark.sql(
    """
    SELECT 
      CO2_Emission_Grams_Mile
    FROM cars 
    where Make = 'Toyota' 
    order by CO2_Emission_Grams_Mile asc
    limit 5
    """
)
toyota_cars = toyota_cars.toPandas().values.tolist()
toyota = ["Toyota"]
for car in toyota_cars:
    clean = str(car).replace('[','')
    clean = str(clean).replace(']','')
    value = float(clean)
    toyota.append(value)

ford_cars = spark.sql(
    """
    SELECT 
      CO2_Emission_Grams_Mile
    FROM cars 
    where Make = 'Ford' 
    order by CO2_Emission_Grams_Mile asc
    limit 5
    """
)
ford_cars = ford_cars.toPandas().values.tolist()
ford = ["Ford"]
for car in ford_cars:
    clean = str(car).replace('[','')
    clean = str(clean).replace(']','')
    value = float(clean)
    ford.append(value)

volkswagen_cars = spark.sql(
    """
    SELECT 
      CO2_Emission_Grams_Mile
    FROM cars 
    where Make = 'Volkswagen' 
    order by CO2_Emission_Grams_Mile asc
    limit 5
    """
)
volkswagen_cars = volkswagen_cars.toPandas().values.tolist()
volkswagen = ["Volkswagen"]
for car in volkswagen_cars:
    clean = str(car).replace('[','')
    clean = str(clean).replace(']','')
    value = float(clean)
    volkswagen.append(value)

nissan_cars = spark.sql(
    """
    SELECT 
      CO2_Emission_Grams_Mile
    FROM cars 
    where Make = 'Nissan' 
    order by CO2_Emission_Grams_Mile asc
    limit 5
    """
)
nissan_cars = nissan_cars.toPandas().values.tolist()
nissan = ["Nissan"]
for car in nissan_cars:
    clean = str(car).replace('[','')
    clean = str(clean).replace(']','')
    value = float(clean)
    nissan.append(value)

honda_cars = spark.sql(
    """
    SELECT 
      CO2_Emission_Grams_Mile
    FROM cars 
    where Make = 'Honda' 
    order by CO2_Emission_Grams_Mile asc
    limit 5
    """
)
honda_cars = honda_cars.toPandas().values.tolist()
honda = ["Honda"]
for car in honda_cars:
    clean = str(car).replace('[','')
    clean = str(clean).replace(']','')
    value = float(clean)
    honda.append(value)
cars = [toyota,ford,volkswagen,nissan,honda]
cars

#Setting result to Q6
answer_dict["Q6"] =  cars
answer_dict["Q6"]

"""##Q7. Form 7 groups of 5 years to calculated the median Combined MPG of each group. The first group is from 1984 to 1988, the second from 1989 to 1993 and so on. The last group will have years not appearing in the dataset.

#####Note: The groups ranges are inclusive on both sides, the first group starts with 1984 and cars from 1984 are included in it.
#####Format : A 7X2 list with the first element of each row being a tuple of two integers being the lower and uppper range of the year groups and the esecond element being the median Combined MPG of that group, a float number.

#####Example answer:


```
[[(1984, 1988), 11.0],
 [(1989, 1993), 10.0],
 [(1994, 1998), 10.0],
 [(1999, 2003), 14.0],
 [(2004, 2008), 13.0],
 [(2009, 2013), 14.0],
 [(2014, 2018), 15.0]]
```


"""

########## Q7
#Your code here
#Getting records per year, avg/mean
groups = spark.sql(
    """
    SELECT 
     '1984,1988', avg(Combined_MPG)
    FROM cars 
    where Year between 1984 and 1988
    UNION 
    SELECT 
    '1989,1993', avg(Combined_MPG)
    FROM cars 
    where Year between 1989 and 1993
   UNION 
    SELECT 
    '1994,1998', avg(Combined_MPG)
    FROM cars 
    where Year between 1994 and 1998
    UNION 
    SELECT 
    '1999,2003', avg(Combined_MPG)
    FROM cars 
    where Year between 1999 and 2003
    UNION 
    SELECT 
    '2004,2008', avg(Combined_MPG)
    FROM cars 
    where Year between 2004 and 2008
    UNION 
    SELECT 
    '2009,2013', avg(Combined_MPG)
    FROM cars 
    where Year between 2009 and 2013
    UNION 
    SELECT 
    '2014,2018', avg(Combined_MPG)
    FROM cars 
    where Year between 2014 and 2018
    """
)

#Checking that the last group avg is the same using 2014 to the present that using 2014 to 2018
groups2 = spark.sql(
      """
    SELECT 
    '2014,2018', avg(Combined_MPG)
    FROM cars 
    where Year >= 2014
    """)
groups.show()

#Converting to list
mean = groups.toPandas().values.tolist()
mean

#Creating tuples and making sure the float type
result = [[],[],[],[],[],[],[]]
i = 0
for group in mean:
  result[i] = [eval(group[0]),float(group[1])]
  i+=1  
result

#Setting result to Q7
answer_dict["Q7"] =  result
answer_dict["Q7"]

"""##Test your answers

##### We provide you some tests to make sure your answer dictionary is in the correct format using unittest.
##### These tests are not meant to be comprehensive, you should review all your answers carefully.
"""

import unittest

class TestAnswers(unittest.TestCase):
    def test_if_dict(self):
        self.assertIsInstance(answer_dict, dict)

    def test_keys(self):
        self.assertEqual(list(answer_dict.keys()), ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7'])

    def test_answers_types(self):
        types_values = [type(k) for k in answer_dict.values()]
        answer_types = [float, list, list, list, list, list, list]
        self.assertEqual(types_values, answer_types)

    def test_Q1(self):
        self.assertEqual(type(answer_dict['Q1']), float)

    def test_Q2_dim(self):
        self.assertEqual(np.array(answer_dict['Q2']).shape, (5,2))

    def test_Q2_types(self):
        dtype1 = type(answer_dict['Q2'][0][0])
        dtype2 = type(answer_dict['Q2'][0][1])
        self.assertEqual([dtype1, dtype2], [str, int])

    def test_Q3_types(self):
        q3_types = set([type(item) for item in answer_dict['Q3']])
        self.assertEqual(q3_types, {str})

    def test_Q4_dim(self):
        self.assertEqual(np.array(answer_dict['Q4']).shape, (9,3))

    def test_Q4_types(self):
        dtype1 = type(answer_dict['Q4'][0][0])
        dtype2 = type(answer_dict['Q4'][0][1])
        dtype3 = type(answer_dict['Q4'][0][2])
        self.assertEqual([dtype1, dtype2, dtype3], [str, int, float])

    def test_Q5_dim(self):
        self.assertEqual(np.array(answer_dict['Q5']).shape, (19,3))

    def test_Q5_types(self):
        dtype1 = type(answer_dict['Q5'][0][0])
        dtype2 = type(answer_dict['Q5'][0][1])
        dtype3 = type(answer_dict['Q5'][0][2])
        self.assertEqual([dtype1, dtype2, dtype3], [int, int, float])

    def test_Q5_first_zero(self):
        self.assertEqual(answer_dict['Q5'][0][2], 0)


    def test_Q6_dim(self):
        self.assertEqual(np.array(answer_dict['Q6']).shape, (5,6))

    def test_Q5_types(self):
        dtype1 = type(answer_dict['Q6'][0][0])
        dtype2 = type(answer_dict['Q6'][0][1])
        dtype3 = type(answer_dict['Q6'][0][2])
        dtype4 = type(answer_dict['Q6'][0][3])
        dtype5 = type(answer_dict['Q6'][0][4])
        dtype6 = type(answer_dict['Q6'][0][5])
        self.assertEqual([dtype1, dtype2, dtype3, dtype4, dtype5, dtype6], [str, float, float, float, float, float])

    def test_Q6_check_first_and_last_brand(self):
        first_brand = answer_dict['Q6'][0][0]
        last_brand = answer_dict['Q6'][4][0]

        self.assertEqual([first_brand, last_brand], ["Toyota", "Honda"])

    def test_Q7_dim(self):
        self.assertEqual(np.array(answer_dict['Q7'], dtype=object).shape, (7,2))

    def test_Q7_types(self):
        dtype1 = type(answer_dict['Q7'][0][0])
        dtype2 = type(answer_dict['Q7'][0][1])
        self.assertEqual([dtype1, dtype2], [tuple, float])

unittest.main(argv=[''], verbosity=2, exit=False)

"""##Save your answers


##### First, take a moment to evaluate your answers and make sure you have not missed anything

##### Use the following code to save your answers in pickle format, change the filename using the following format:
##### FIRSTNAME_LASTNAME_answers.pkl
##### Example: Juan_Perez_answers.pkl

##### If you are using google colab you can find your file on the left side bar by clicking the folder icon inside the sample_data folder. Remember to upload the pickle file and the notebook to github and submit their URLs to the [google form](https://forms.gle/wWysZEMkoZsjB11Y7).
"""

answer_dict

import pickle

file_name = "MIGUEL_LOPEZ_answers.pkl"
path = ""

with open(path+file_name, 'wb') as f:
    pickle.dump(answer_dict, f, protocol=pickle.HIGHEST_PROTOCOL)